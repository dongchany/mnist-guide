# 第 11 章：工程实践——测试、调试与项目组织

> **本章目标**：学会用梯度检验验证代码正确性，编写单元测试，以及组织一个干净的项目。
> **预计时间**：2 小时

---

## 11.1 为什么需要测试？

从零写反向传播，你面临一个残酷的事实：**代码能跑 ≠ 代码正确**。

一个梯度计算中的小 bug（比如漏除了 N，转置搞反了），网络依然会"训练"，损失甚至可能下降——只是学得慢一点、差一点。你可能永远不知道 bug 的存在。

测试是你的安全网。

---

## 11.2 梯度检验：终极调试武器

### 原理

用**数值方法**独立计算梯度，然后和你的反向传播（解析梯度）对比。

数值梯度用中心差分法：

```
∂L/∂wᵢ ≈ [L(wᵢ + ε) - L(wᵢ - ε)] / (2ε)
```

把每个参数依次微调 ±ε，观察损失变化。虽然慢（要对每个参数算两次前向传播），但几乎不可能算错。

### 相对误差

比较两个梯度时，不能用绝对差（因为梯度本身可能很大或很小），要用相对误差：

```
relative_error = |analytical - numerical| / max(|analytical| + |numerical|, 1e-8)
```

- 相对误差 < 1e-5：通过
- 相对误差 > 1e-3：几乎一定有 bug

### 代码

```python
def numerical_gradient(loss_fn, param, eps=1e-5):
    """Compute gradient numerically using central difference."""
    grad = np.zeros_like(param)
    it = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        old = param[idx]
        
        param[idx] = old + eps
        loss_plus = loss_fn()
        param[idx] = old - eps
        loss_minus = loss_fn()
        param[idx] = old
        
        grad[idx] = (loss_plus - loss_minus) / (2 * eps)
        it.iternext()
    return grad
```

### 使用方式

```python
# Create a small network (gradient check is slow, so keep it tiny!)
model = FullyConnectedNetwork(layer_sizes=[4, 5, 3], verbose=False)
X = np.random.randn(3, 4)
y_oh = np.zeros((3, 3))
y_oh[np.arange(3), [0, 1, 2]] = 1.0

# Get analytical gradients
acts, pre = model._forward(X)
grad_w, grad_b = model._backward(acts, pre, y_oh)

# Define loss function for numerical gradient
def loss_fn():
    a, _ = model._forward(X)
    return -np.mean(np.sum(y_oh * np.log(np.clip(a[-1], 1e-12, 1.0)), axis=1))

# Compare
for i in range(model.num_layers):
    num_gw = numerical_gradient(loss_fn, model.weights[i])
    err = np.max(np.abs(grad_w[i] - num_gw) / 
                 np.maximum(np.abs(grad_w[i]) + np.abs(num_gw), 1e-8))
    print(f"Layer {i} weight gradient error: {err:.2e}")
    assert err < 1e-5, f"FAIL! Error too large: {err}"
```

**重要**：梯度检验只在小网络、少样本上做（否则太慢）。通过后就可以放心地在大数据上训练了。

---

## 11.3 需要检验哪些梯度？

按重要性排序：

| 检验对象 | 为什么重要 |
|---|---|
| **FC 各层权重/偏置** | 反向传播的核心，最容易写错 |
| **卷积层 dW, db** | im2col 涉及复杂的索引操作 |
| **卷积层 dX** | col2im 更容易出错 |
| **池化层 dX** | mask 逻辑容易有边界 bug |
| **端到端 CNN** | 验证所有层串联后梯度依然正确 |

### CNN 的实用技巧

CNN 参数多，全量检验太慢。可以只**抽样检查**部分参数：

```python
# Spot-check 10 random parameters in conv1_w
eps = 1e-5
for _ in range(10):
    idx = tuple(np.random.randint(0, s) for s in model.conv1_w.shape)
    old = model.conv1_w[idx]
    
    model.conv1_w[idx] = old + eps
    loss_plus = compute_loss()
    model.conv1_w[idx] = old - eps
    loss_minus = compute_loss()
    model.conv1_w[idx] = old
    
    numerical = (loss_plus - loss_minus) / (2 * eps)
    analytical = grads['conv1_w'][idx]
    
    error = abs(numerical - analytical) / max(abs(numerical) + abs(analytical), 1e-8)
    assert error < 1e-4, f"Error at {idx}: {error:.2e}"
```

---

## 11.4 单元测试：用 unittest 框架

Python 自带 `unittest` 框架，无需安装。基本结构：

```python
import unittest

class TestMyCode(unittest.TestCase):
    
    def test_something(self):
        """Each test method starts with 'test_'."""
        result = 1 + 1
        self.assertEqual(result, 2)
    
    def test_array_close(self):
        """For floating point, use assertAlmostEqual or numpy assertions."""
        a = np.array([1.0000001])
        np.testing.assert_allclose(a, [1.0], atol=1e-5)

if __name__ == '__main__':
    unittest.main()
```

运行：`uv run python tests.py -v`（或激活环境后直接 `python tests.py -v`）

### 我们项目中的测试分类

**1. 梯度检验**（最关键）：验证反向传播正确性。

**2. 形状测试**：确保每一层输出的维度符合预期。

```python
def test_forward_shapes(self):
    model = FullyConnectedNetwork(layer_sizes=[784, 64, 32, 10], verbose=False)
    acts, _ = model._forward(np.random.randn(8, 784))
    self.assertEqual(acts[-1].shape, (8, 10))
```

**3. 指标测试**：用 sklearn 交叉验证自己实现的指标。

```python
def test_accuracy_matches_sklearn(self):
    import sklearn.metrics as skm
    ours = compute_all_metrics(y_true, y_pred)['accuracy']
    theirs = skm.accuracy_score(y_true=y_true, y_pred=y_pred)
    self.assertAlmostEqual(ours, theirs, places=10)
```

**4. 数值稳定性测试**：极端输入不崩溃。

```python
def test_softmax_large_input(self):
    z = np.array([[1000, 1001, 999]])
    s = softmax(z)
    self.assertTrue(np.all(np.isfinite(s)))           # no inf/nan
    np.testing.assert_allclose(s.sum(axis=1), 1.0)    # sums to 1
```

**5. 烟雾测试**：模型能在小数据集上过拟合。

```python
def test_fc_can_overfit(self):
    X = np.random.randn(10, 784) * 0.1
    y = np.arange(10)
    model = FullyConnectedNetwork(layer_sizes=[784, 32, 10],
                                   learning_rate=0.5, epochs=100, verbose=False)
    model.fit(X, y)
    self.assertGreater(np.mean(model.predict(X) == y), 0.8)
```

如果连 10 个样本都记不住，反向传播一定有 bug。

---

## 11.5 项目文件组织

一个干净的项目结构：

```
project/
├── activations.py      # 共享的激活函数与工具
├── fc_network.py       # FC 网络实现
├── cnn_network.py      # CNN 实现
├── metrics.py          # 评估指标
├── data_loader.py      # 数据加载与预处理
├── plotting.py         # 可视化函数
├── main.py             # 训练与评估主脚本
├── generate_report.py  # 自动生成 PDF 报告
├── tests.py            # 测试套件
└── README.md           # 项目说明
```

**原则**：
- **单一职责**：每个文件做一件事
- **避免重复**：relu 只定义一次，放在 activations.py
- **公共模块提取**：FC 和 CNN 都用的函数（relu、softmax、loss）放在共享模块中
- **测试独立**：tests.py 不依赖 MNIST 数据，用随机小数据即可运行

---

## 11.6 常见 Bug 及调试技巧

### Bug 1：维度不匹配

**症状**：`ValueError: shapes not aligned`

**排查**：在每一步打印 shape。

```python
print(f"X: {X.shape}, W: {W.shape}, result: {(X @ W).shape}")
```

### Bug 2：梯度计算错误

**症状**：训练 loss 下降缓慢或震荡。

**排查**：用梯度检验！通常原因是忘了除以 N，或者转置搞反了。

### Bug 3：数值不稳定

**症状**：loss 变成 NaN 或 inf。

**排查**：检查 softmax 是否减了最大值，cross-entropy 是否 clip 了。

### Bug 4：学习率太大

**症状**：loss 震荡甚至增大。

**排查**：先试一个很小的学习率（如 0.001），确认 loss 在下降，再逐步调大。

### 通用技巧

```python
# Assert no NaN/Inf in critical tensors
assert np.all(np.isfinite(probs)), "NaN detected in softmax output!"

# Check probability sums
assert np.allclose(probs.sum(axis=1), 1.0), "Softmax doesn't sum to 1!"
```

---

## 11.7 动手练习

**练习 1**：给你的 FC 网络添加完整的梯度检验。故意把反向传播改错一点（比如去掉 `/m`），观察梯度检验是否能发现错误。

**练习 2**：为 metrics.py 中的所有指标编写单元测试，用手算的已知结果做验证。

**练习 3**：运行项目中的完整测试套件（`uv run python tests.py`），确保全部通过。

---

## 11.8 本教程总结

恭喜你完成了整个教程！让我们回顾你学到了什么：

**你从零实现了**：
- 全连接神经网络（前向传播 + 反向传播 + 训练循环）
- 卷积神经网络（im2col 卷积 + 最大池化）
- 8 种分类指标
- 梯度显著性图
- 完整的测试套件

**你理解了**：
- 神经元是加权求和 + 非线性激活
- 多层网络通过链式法则学习（反向传播）
- 交叉熵损失衡量预测概率与真实标签的差距
- 卷积利用局部连接和参数共享处理图像
- 测试是工程实践的核心

**下一步建议**：
- 用 PyTorch 重写这个项目，体会框架的便利
- 在更复杂的数据集（CIFAR-10、Fashion-MNIST）上实验
- 学习更多技巧：Dropout、Batch Normalization、Adam 优化器
- 探索更深的网络：ResNet、VGG 等经典架构
