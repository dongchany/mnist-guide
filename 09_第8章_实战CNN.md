# 第 8 章：实战——CNN 从零开始

> **本章目标**：实现完整的 CNN 代码，训练并与 FC 网络对比。
> **预计时间**：2.5 小时

---

## 8.1 整体代码结构

CNN 和 FC 网络共享 `activations.py`，只需新建 `cnn_network.py`：

```python
# cnn_network.py — outline
import numpy as np
from activations import relu, relu_derivative, softmax, cross_entropy_loss

# 1. im2col / conv_forward / conv_backward
# 2. maxpool_forward / maxpool_backward
# 3. ConvolutionalNetwork class
```

---

## 8.2 卷积层实现

### 前向传播

```python
def conv_forward(X, W, b, stride=1, pad=0):
    """
    X: (N, C_in, H, W)    — input images
    W: (C_out, C_in, kh, kw) — filters
    b: (C_out,)            — biases
    Returns: output (N, C_out, out_h, out_w), cache for backward
    """
    N = X.shape[0]
    C_out = W.shape[0]
    col, out_h, out_w = im2col(X, W.shape[2], W.shape[3], stride, pad)
    
    # Matrix multiply: each row of col × each filter
    out = (col @ W.reshape(C_out, -1).T + b)
    out = out.reshape(N, out_h, out_w, C_out).transpose(0, 3, 1, 2)
    
    cache = (X, W, b, col, out_h, out_w, stride, pad)
    return out, cache
```

**解读**：
- `im2col` 把输入展开成 (N·oh·ow, C_in·kh·kw) 的矩阵
- `W.reshape(C_out, -1).T` 把滤波器变成 (C_in·kh·kw, C_out) 的矩阵
- 一次矩阵乘法完成所有卷积

### 反向传播

```python
def conv_backward(dout, cache):
    """Compute gradients for X, W, b given upstream gradient dout."""
    X, W, b, col, out_h, out_w, stride, pad = cache
    N, C_in, H, Wid = X.shape
    C_out, _, kh, kw = W.shape
    
    dout_r = dout.transpose(0, 2, 3, 1).reshape(-1, C_out)
    W_col = W.reshape(C_out, -1).T
    
    # Gradients for weights and biases
    dW = (col.T @ dout_r).T.reshape(W.shape)
    db = np.sum(dout_r, axis=0)
    
    # Gradient for input (col2im)
    dcol = (dout_r @ W_col.T).reshape(N, out_h, out_w, C_in, kh, kw).transpose(0,3,4,5,1,2)
    dX = np.zeros((N, C_in, H + 2*pad, Wid + 2*pad)) if pad > 0 else np.zeros_like(X)
    for i in range(kh):
        for j in range(kw):
            dX[:, :, i:i+stride*out_h:stride, j:j+stride*out_w:stride] += dcol[:, :, i, j]
    if pad > 0:
        dX = dX[:, :, pad:-pad, pad:-pad]
    
    return dX, dW, db
```

---

## 8.3 池化层实现

```python
def maxpool_forward(X, pool_size=2, stride=2):
    """Max pooling: take max of each pool_size × pool_size block."""
    N, C, H, W = X.shape
    oh, ow = H // stride, W // stride
    out = np.zeros((N, C, oh, ow))
    mask = np.zeros_like(X)  # remember which element was max
    
    for i in range(oh):
        for j in range(ow):
            patch = X[:, :, i*stride:i*stride+pool_size, j*stride:j*stride+pool_size]
            out[:, :, i, j] = np.max(patch, axis=(2, 3))
            # Record max positions for backward pass
            mask[:, :, i*stride:i*stride+pool_size, j*stride:j*stride+pool_size] += \
                (patch == out[:, :, i, j][:, :, None, None])
    
    return out, (X, mask, pool_size, stride)


def maxpool_backward(dout, cache):
    """Route gradients back to the max positions."""
    X, mask, pool_size, stride = cache
    oh, ow = dout.shape[2], dout.shape[3]
    dX = np.zeros_like(X)
    
    for i in range(oh):
        for j in range(ow):
            m = mask[:, :, i*stride:i*stride+pool_size, j*stride:j*stride+pool_size]
            m_sum = np.maximum(np.sum(m, axis=(2, 3), keepdims=True), 1)
            dX[:, :, i*stride:i*stride+pool_size, j*stride:j*stride+pool_size] += \
                (m / m_sum) * dout[:, :, i, j][:, :, None, None]
    
    return dX
```

**反向传播的直觉**：梯度只流向前向时的"最大值"位置。如果一个像素不是最大值，它对输出没有贡献，梯度为 0。

---

## 8.4 CNN 类

结构和 FC 类似，只是前向和反向传播多了卷积和池化步骤：

```python
class ConvolutionalNetwork:
    def __init__(self, learning_rate=0.01, epochs=3, batch_size=32):
        self.lr = learning_rate
        self.epochs = epochs
        self.batch_size = batch_size
        
        # Conv1: 1 → 4 filters
        self.conv1_w = np.random.randn(4, 1, 3, 3) * np.sqrt(2.0 / 9)
        self.conv1_b = np.zeros(4)
        # Conv2: 4 → 8 filters
        self.conv2_w = np.random.randn(8, 4, 3, 3) * np.sqrt(2.0 / 36)
        self.conv2_b = np.zeros(8)
        # FC1: 392 → 32
        self.fc1_w = np.random.randn(392, 32) * np.sqrt(2.0 / 392)
        self.fc1_b = np.zeros((1, 32))
        # FC2: 32 → 10
        self.fc2_w = np.random.randn(32, 10) * np.sqrt(2.0 / 32)
        self.fc2_b = np.zeros((1, 10))
```

前向传播按层串联，反向传播按相反顺序。训练循环和 FC 网络完全相同（遍历 epoch → 遍历 batch → forward → backward → update），这也是我们在第 6 章中已经学过的模式。

---

## 8.5 训练与对比

```python
from data_loader import load_mnist, preprocess_for_cnn

X_train, y_train, X_test, y_test = load_mnist('./MNIST_data')
X_train_cnn, X_test_cnn = preprocess_for_cnn(X_train, X_test)

# Use 3000 samples (pure NumPy CNN is slow!)
idx = np.random.choice(60000, 3000, replace=False)

model = ConvolutionalNetwork(learning_rate=0.01, epochs=3, batch_size=32)
model.fit(X_train_cnn[idx], y_train[idx])

test_acc = np.mean(model.predict(X_test_cnn) == y_test)
print(f"CNN Test Accuracy: {test_acc:.4f}")
```

### FC vs CNN 对比

| | FC 网络 | CNN |
|---|---|---|
| 参数量 | 52,650 | 13,242 |
| 训练样本 | 10,000 | 3,000 |
| 训练时间 | ~30秒 | ~2分钟 |
| 测试准确率 | ~93% | ~88% |

CNN 用更少的参数和训练数据就能达到不错的效果。如果给它更多数据和训练时间，会超过 FC 网络，因为卷积结构天然适合图像任务。

---

## 8.6 为什么 CNN 纯 NumPy 很慢？

我们的 im2col + 矩阵乘法已经比嵌套循环快很多了，但和 PyTorch/TensorFlow 相比还是慢 10–100 倍，因为：

1. 框架使用 **GPU**，可以同时做上千次乘法
2. 框架的 C++/CUDA 实现比 Python 快得多
3. 框架有更多优化（内存复用、算子融合等）

但我们的目标不是追求速度，而是**理解每一步在做什么**。这种理解在你以后使用框架时非常有价值。

---

## 8.7 动手练习

**练习 1**：训练完成后，可视化 `model.conv1_w` 的 4 个 3×3 滤波器。它们学到了什么模式？

**练习 2**：增大 CNN 的滤波器数量（比如 8→16→32），观察准确率和训练时间的变化。

**练习 3**：对比同样训练 3000 个样本时，FC 和 CNN 的准确率差异。
